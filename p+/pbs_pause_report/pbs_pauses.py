#!/usr/bin/env python3

""" A module to parse the OUTPUT.tar.gz file generated by the TCS software system to look for
  Abnormal Beam conditions between when TDS=BEAM_ON and TDS=TERMINATE

  Usage:  pbs_beam_detections.py /directory_to_OUTPUT.tar.gz files.
    ** If on Linux / Unix make sure to chmod +x the script before trying this.
"""

import tarfile
#import psycopg2
from pprint import pprint
import file_utilities
import treatment_parser
import scanning_parser
from postgres import Postgres
from decimal import Decimal


def fields_around_90(treatments):
    fields = []
    for treatment in treatments:
        if treatment.positions.gantry > Decimal(70.0):
            if treatment.positions.gantry < Decimal(110.0):
                fields.append(treatment)
    return fields


def y_pos_by_date(treatments):
    categories = {}
    fields = 0
    total_pauses = 0
    for treatment in treatments:
        fields += 1
        field_pauses = 0
        pauses = treatment.all_pauses()
        for pause in pauses:
            if pause.type == 'Y_POS':
                field_pauses += 1
        print('Date: {}, Y_POS: {}, Gantry: {}, Range: {}, Snout: {}'.format(treatment.start_time.strftime('%Y-%m-%d %H:%M:%S,%f'),
                                                                  field_pauses, treatment.positions.gantry,
                                                                  treatment.max_range, treatment.positions.snout))
        total_pauses += field_pauses

    if total_pauses != 0:
        rate = float(total_pauses / fields)
    else:
        rate = 0

    # Get the date from the first treatment
    if len(treatments) != 0:
        print('Date: {}'.format(treatments[0].start_time.strftime("%m-%d-%Y")))
        print("Total Fields: {}, Total Pauses: {}, Pause Rate: {:.2f}".format(fields, total_pauses, rate))
        print(categories)


def daily_pause_category(treatments, details=False):
    categories = {}
    fields = 0
    total_pauses = 0
    for treatment in treatments:
        fields += 1
        if details:
            print(treatment)
        pauses = treatment.all_pauses()
        for pause in pauses:
            total_pauses += 1
            if pause.type in categories:
                categories[pause.type] = categories[pause.type] + 1
            else:
                categories[pause.type] = 1
    if total_pauses != 0:
        rate = float(total_pauses / fields)
    else:
        rate = 0

    # Get the date from the first treatment
    if len(treatments) != 0:
        print('Date: {}'.format(treatments[0].start_time.strftime("%m-%d-%Y")))
        print("Total Fields: {}, Total Pauses: {}, Pause Rate: {:.2f}".format(fields, total_pauses, rate))
        pprint(categories)


def main(directory):
    """ Main program flow that will take a path to the directory containing OUTPUT.tar.gz files
    and parse them. First by finding the time when each treatment started and the time the first layer
    is started for a field. It then calculates the dose delivered in this time and outputs it to a csv file.

    Args:
        directory: Path that contains all Output.tar.gz files for a site.

    Returns:
        None
    """
    treatments = []
    room = 2
    for zipped_tarballs in file_utilities.find_tar_gz_files(directory):
        for tarball in file_utilities.find_tar_files_in_tarball(zipped_tarballs):
            with tarfile.open(fileobj=tarball) as f:  # This loops through each tar.gz file
                # Parse each treatment process room log and add to treatments
                treatment_logs = scanning_parser.iteration_generator(file_utilities.find_process_log_file_in_tarfile(
                    f, '^pts-treat-proc-{}'.format(room)))
                for log in treatment_logs:  # We must parse all treatment logs found, in case of room restarts.
                    treatments.extend(treatment_parser.parse_treatment_file(log, room))  # Use extend on list.
                # Take all treatments found and find the dose for each from PBSDR log
                scanning_controller_logs = file_utilities.find_process_log_file_in_tarfile(f, '^pts-scanning')
                for slog in scanning_controller_logs:  # We must parse all scanning controller logs found
                    scanning_parser.parse_scanning_controller_file(slog, treatments)
                # Go through list of fields for each day and create a report.
                # Reset the treatments after each tar file is parsed.
                # daily_pause_category(treatments)
                """ Record the days fields, pauses, and positions into the database."""
                #                conn = psycopg2.connect("dbname=stats user=postgres password=postgres host=10.1.40.221 port=5432")
                #                with conn:
                #                    with conn.cursor as cur:
                #                        for treatment in treatments:
                #                            treatment.record(cur)
                #                conn.close()
                daily_pause_category(treatments)
                treatments = []

    for tarred_file in file_utilities.find_tar_files(directory):
        with tarfile.open(tarred_file, "r") as f:  # This loops through each tar file
            treatment_logs = scanning_parser.iteration_generator(file_utilities.find_process_log_file_in_tarfile(
                f, '^pts-treat-proc-{}'.format(room)))
            for log in treatment_logs:  # We must parse all treatment logs found, in case of room restarts.
                treatments.extend(treatment_parser.parse_treatment_file(log, room))  # Use extend on list.
                # Take all treatments found and find the dose for each from PBSDR log
                scanning_controller_logs = file_utilities.find_process_log_file_in_tarfile(f, '^pts-scanning')
                for slog in scanning_controller_logs:  # We must parse all scanning controller logs found
                    scanning_parser.parse_scanning_controller_file(slog, treatments)
                    # Go through list of fields for each day and create a report.
                    # Reset the treatments after each tar file is parsed.
                    # daily_pause_category(treatments)
                    """ Record the days fields, pauses, and positions into the database."""
                    #                conn = psycopg2.connect("dbname=stats user=postgres password=postgres host=10.1.40.221 port=5432")
                    #                with conn:
                    #                    with conn.cursor as cur:
                    #                        for treatment in treatments:
                    #                            treatment.record(cur)
                    #                conn.close()
                    daily_pause_category(treatments)
                    treatments = []

    treatment_logs = file_utilities.find_process_log_file_in_directory(directory, 'pts-treat-proc-{}'.format(room))
    for process_log in treatment_logs:
        treatments.extend(treatment_parser.parse_treatment_file(process_log, room, False))
        scanning_controller_logs = file_utilities.find_process_log_file_in_directory(directory, 'pts-scanning')
        for slog in scanning_controller_logs:
            scanning_parser.parse_scanning_controller_file(slog, treatments)
            daily_pause_category(treatments)
            treatments = []


main('/p+/runtimeStore/log/Archive/')


"""
if __name__ == '__main__':
    main(sys.argv[1])
"""
